llm4s {
  llm {
    # Default model for samples; can be overridden by env or -D.
    # Example: LLM_MODEL=ollama/llama3:latest
    model = "ollama/llama3:latest"
    model = ${?LLM_MODEL}
  }

  ollama {
    # Default Ollama base URL for samples; can be overridden by env or -D.
    baseUrl = "http://localhost:11434"
    baseUrl = ${?OLLAMA_BASE_URL}
  }
}

# Optional per-developer overlay; if present, its values override the above.
# Example (in application.local.conf):
# llm4s {
#   llm.model     = "ollama/deepseek-r1:8b"
#   ollama.baseUrl = "http://100.75.7.118:11434"
# }
include "application.local.conf"
