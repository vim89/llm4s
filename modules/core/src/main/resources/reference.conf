# Unified llm4s configuration namespace
llm4s {
  # Primary model selection, e.g. "openai/gpt-4o", "anthropic/claude-3-7-sonnet-latest", "ollama/llama3.1"
  llm {
    model = ${?LLM_MODEL}
  }

  # OpenAI (also used for OpenRouter via baseUrl)
  openai {
    # Safe default; can be overridden by env or -D
    baseUrl = "https://api.openai.com/v1"
    baseUrl = ${?OPENAI_BASE_URL}
    apiKey  = ${?OPENAI_API_KEY}
    organization = ${?OPENAI_ORGANIZATION}
  }

  # Azure OpenAI
  azure {
    endpoint   = ${?AZURE_API_BASE}
    apiKey     = ${?AZURE_API_KEY}
    apiVersion = ${?AZURE_API_VERSION}
  }

  # Anthropic
  anthropic {
    baseUrl = "https://api.anthropic.com"
    baseUrl = ${?ANTHROPIC_BASE_URL}
    apiKey  = ${?ANTHROPIC_API_KEY}
  }

  # Ollama (local models)
  ollama {
    baseUrl = ${?OLLAMA_BASE_URL}
  }

  # Tracing: Langfuse (app/runners may use these)
  tracing {
    # Tracing mode: langfuse | console | noop
    mode = "console"
    mode = ${?TRACING_MODE}
    langfuse {
      url       = ${?LANGFUSE_URL}
      publicKey = ${?LANGFUSE_PUBLIC_KEY}
      secretKey = ${?LANGFUSE_SECRET_KEY}
      env       = ${?LANGFUSE_ENV}
      release   = ${?LANGFUSE_RELEASE}
      version   = ${?LANGFUSE_VERSION}
    }
  }

  # Embeddings configuration
  embeddings {
    provider  = ${?EMBEDDING_PROVIDER}
    inputPath = ${?EMBEDDING_INPUT_PATH}
    query     = ${?EMBEDDING_QUERY}

    openai {
      baseUrl = ${?OPENAI_EMBEDDING_BASE_URL}
      model   = ${?OPENAI_EMBEDDING_MODEL}
    }

    voyage {
      apiKey  = ${?VOYAGE_API_KEY}
      baseUrl = ${?VOYAGE_EMBEDDING_BASE_URL}
      model   = ${?VOYAGE_EMBEDDING_MODEL}
    }

    chunking {
      size    = ${?CHUNK_SIZE}
      overlap = ${?CHUNK_OVERLAP}
      enabled = ${?CHUNKING_ENABLED}
    }
  }

  # Runner-only convenience (apps may use):
  workspace {
    path = ${?WORKSPACE_PATH}
  }
}
